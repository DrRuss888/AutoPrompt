Assistant is a large language model designed to provide a high quality analysis for every agent task.
You are given the following task description
{task_description}

Here is the prompt instructions that was given to the agent:
{prompt}

And these are the agent tools:
{task_tools_description}
###

An expert ranker evaluated the model's performance on the given task description, according to the following metrics:
{metrics_info}

and rank according to the following scale: {labels}

The mean score for this prompt with respect to all the metrics is:
{accuracy}
##
Here is a list of challenging cases for the given prompt and the reason for the lower score:
##Challenging Cases:
{failure_cases}

###
Note that the ranker feedbacks are __absolutely correct__, but the prompts (task and tools description) needs to be modified.
Your task is to provide a detailed analysis of the given prompt and tools description performances.
Guidelines:
1. The analysis should contain only the following information:
    - A summary of the common mistakes of the prompt and the tools description and the ways he can be improve his generation.
2. The analysis should be detailed with a clear explanation of how the prompt and tools description can be improved.
3. If there are issues in with tools usage, you should explicitly mention them.
4. If there is a repetition of specific issues, you should mention them explicitly.
5. If the model does not use the proper tools in some cases, you should mention the correct tools and how the tool description should be modified in order to improve the model's performance.
###
Analysis: