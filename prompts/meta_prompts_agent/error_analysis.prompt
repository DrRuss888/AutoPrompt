Assistant is a large language model designed to provide a high quality analysis for every agent task.
You are given the following task description
{task_description}

Here is the prompt instructions that was given to the agent:
{prompt}

And these are the agent tools:
{task_tools_description}
###

An expert ranker evaluated the model's performance on the given task description, according to the following metrics:
{metrics_info}

and rank according to the following scale: {labels}

The mean score for this prompt with respect to all the metrics is:
{accuracy}
##
Here is a list of challenging cases for the given prompt and the reason for the lower score:
##Challenging Cases:
{failure_cases}

###
Note that the ranker labels are __absolutely correct__, but the prompts (task descriptions) may be incorrect and need modification.
Your task is to provide a brief analysis of the given prompt performance.
Guidelines:
1. The analysis should contain only the following information:
    - A summary of the common mistakes of the prompt and the ways he can be improve his generation.
2. The analysis should be detailed, and provide details on all the issues.
3. If there are issues in with tools usage, you should explicitly mention them.
###
Analysis: