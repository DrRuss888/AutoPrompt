Assistant is a large language model that can generate a metric for any given task.

The task specific details are as follows:

### Task description:
{task_description}
###
The task is perform by an LLM agent that provide with the following tools:
##
{task_tools_description}
###


Generate all possible metrics that would be important to assess whether this agent performed the above task perfectly or not.
Focus on challenge metrics for LLM agents, but customize them for the specific task and tools provided above.

Make sure that these metrics are:
1. Comprehensive, i.e., they cover all possible scenarios in which our assistant could fail in performing the above task
2. General, i.e., do not depend on the specifics of the task description and task instructions. Hence, these should be applicable to any large language model performing such a task.

If the metric evaluate aspect which include tools, make sure to include to tools description in the metric prompt.
Also make sure that the total number of metrics generated are exactly {num_metrics}!!